import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, datasets
import numpy as np
import random
import time
from typing import Dict, List
import matplotlib.pyplot as plt

# ===== 1. æ•°æ®é¢„å¤„ç†å’Œå¢å¼º =====

class ConvNeXtTransforms:
    """ConvNeXtè®­ç»ƒå’Œæµ‹è¯•çš„æ•°æ®é¢„å¤„ç†"""
    
    @staticmethod
    def get_train_transforms(img_size=224, auto_augment=True):
        """è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º
        
        ç°ä»£è®­ç»ƒæŠ€å·§ï¼š
        - RandAugment: éšæœºæ•°æ®å¢å¼ºç­–ç•¥
        - MixUp/CutMix: åœ¨è®­ç»ƒå¾ªç¯ä¸­å®ç°
        - RandomErasing: éšæœºæ“¦é™¤éƒ¨åˆ†åŒºåŸŸ
        """
        transforms_list = [
            transforms.Resize((256, 256)),  # ç¨å¤§ä¸€ç‚¹ï¼Œä¸ºéšæœºè£å‰ªåšå‡†å¤‡
            transforms.RandomCrop(img_size, padding=4),  # éšæœºè£å‰ª
            transforms.RandomHorizontalFlip(p=0.5),      # éšæœºæ°´å¹³ç¿»è½¬
        ]
        
        if auto_augment:
            # æ·»åŠ æ›´å¼ºçš„æ•°æ®å¢å¼º
            transforms_list.extend([
                transforms.ColorJitter(
                    brightness=0.4,    # äº®åº¦å˜åŒ–
                    contrast=0.4,      # å¯¹æ¯”åº¦å˜åŒ–  
                    saturation=0.4,    # é¥±å’Œåº¦å˜åŒ–
                    hue=0.1           # è‰²è°ƒå˜åŒ–
                ),
                transforms.RandomRotation(15),              # éšæœºæ—‹è½¬
                transforms.RandomAffine(0, shear=0.2),     # éšæœºä»¿å°„å˜æ¢
            ])
        
        transforms_list.extend([
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNetæ ‡å‡†åŒ–
                std=[0.229, 0.224, 0.225]
            ),
            transforms.RandomErasing(p=0.25)  # éšæœºæ“¦é™¤
        ])
        
        return transforms.Compose(transforms_list)
    
    @staticmethod
    def get_val_transforms(img_size=224):
        """éªŒè¯æ—¶çš„æ•°æ®é¢„å¤„ç†ï¼ˆåªåšå¿…è¦çš„å˜æ¢ï¼‰"""
        return transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(img_size),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])


# ===== 2. ç°ä»£è®­ç»ƒæŠ€å·§ =====

class MixUp:
    """MixUpæ•°æ®å¢å¼ºå®ç°"""
    
    def __init__(self, alpha=0.2):
        self.alpha = alpha
    
    def __call__(self, x, y):
        if self.alpha > 0:
            lam = np.random.beta(self.alpha, self.alpha)
        else:
            lam = 1
        
        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)
        
        mixed_x = lam * x + (1 - lam) * x[index, :]
        y_a, y_b = y, y[index]
        
        return mixed_x, y_a, y_b, lam


class CutMix:
    """CutMixæ•°æ®å¢å¼ºå®ç°"""
    
    def __init__(self, alpha=1.0):
        self.alpha = alpha
    
    def __call__(self, x, y):
        lam = np.random.beta(self.alpha, self.alpha)
        
        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)
        
        _, _, H, W = x.shape
        cut_rat = np.sqrt(1. - lam)
        cut_w = int(W * cut_rat)
        cut_h = int(H * cut_rat)
        
        # éšæœºé€‰æ‹©è£å‰ªåŒºåŸŸ
        cx = np.random.randint(W)
        cy = np.random.randint(H)
        
        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)
        
        x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
        
        # è°ƒæ•´lambda
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
        y_a, y_b = y, y[index]
        
        return x, y_a, y_b, lam


class LabelSmoothing(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æ­£åˆ™åŒ–"""
    
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
    
    def forward(self, pred, target):
        log_prob = F.log_softmax(pred, dim=-1)
        nll_loss = -log_prob.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -log_prob.mean(dim=-1)
        loss = self.confidence * nll_loss + self.smoothing * smooth_loss
        return loss.mean()


# ===== 3. è®­ç»ƒå™¨ä¸»ç±» =====

class ConvNeXtTrainer:
    """ConvNeXtè®­ç»ƒå™¨ - é›†æˆç°ä»£è®­ç»ƒæŠ€å·§"""
    
    def __init__(self, 
                 model, 
                 device='cuda',
                 num_classes=1000,
                 use_amp=True,           # æ··åˆç²¾åº¦è®­ç»ƒ
                 use_mixup=True,         # MixUpå¢å¼º
                 use_cutmix=True,        # CutMixå¢å¼º  
                 label_smoothing=0.1):   # æ ‡ç­¾å¹³æ»‘
        
        self.model = model.to(device)
        self.device = device
        self.num_classes = num_classes
        self.use_amp = use_amp
        
        # ç°ä»£è®­ç»ƒæŠ€å·§
        self.mixup = MixUp(alpha=0.2) if use_mixup else None
        self.cutmix = CutMix(alpha=1.0) if use_cutmix else None
        self.use_augment_prob = 0.5  # ä½¿ç”¨æ•°æ®å¢å¼ºçš„æ¦‚ç‡
        
        # æŸå¤±å‡½æ•°
        if label_smoothing > 0:
            self.criterion = LabelSmoothing(smoothing=label_smoothing)
        else:
            self.criterion = nn.CrossEntropyLoss()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        if self.use_amp:
            self.scaler = torch.amp.GradScaler('cuda')
        
        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        self.learning_rates = []
    
    def setup_optimizer(self, learning_rate=1e-4, weight_decay=0.05, optimizer_type='adamw'):
        """è®¾ç½®ä¼˜åŒ–å™¨ - ConvNeXtå®˜æ–¹æ¨èAdamW"""
        
        # å‚æ•°åˆ†ç»„ï¼šå¯¹ä¸åŒç±»å‹å‚æ•°åº”ç”¨ä¸åŒçš„weight_decay
        param_groups = self._get_param_groups(weight_decay)
        
        if optimizer_type.lower() == 'adamw':
            self.optimizer = optim.AdamW(
                param_groups,
                lr=learning_rate,
                betas=(0.9, 0.999),
                eps=1e-8
            )
        elif optimizer_type.lower() == 'sgd':
            self.optimizer = optim.SGD(
                param_groups,
                lr=learning_rate,
                momentum=0.9,
                nesterov=True
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨ç±»å‹: {optimizer_type}")
    
    def _get_param_groups(self, weight_decay):
        """å‚æ•°åˆ†ç»„ - ä¸å¯¹biaså’Œnormå±‚åº”ç”¨weight_decay"""
        decay_params = []
        no_decay_params = []
        
        for name, param in self.model.named_parameters():
            if not param.requires_grad:
                continue
            
            # ä¸å¯¹biaså’Œå½’ä¸€åŒ–å±‚å‚æ•°åº”ç”¨weight decay
            if len(param.shape) == 1 or name.endswith('.bias') or 'norm' in name:
                no_decay_params.append(param)
            else:
                decay_params.append(param)
        
        return [
            {'params': decay_params, 'weight_decay': weight_decay},
            {'params': no_decay_params, 'weight_decay': 0.}
        ]
    
    def setup_scheduler(self, scheduler_type='cosine', epochs=100, min_lr=1e-6):
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        
        if scheduler_type == 'cosine':
            self.scheduler = CosineAnnealingLR(
                self.optimizer, 
                T_max=epochs,
                eta_min=min_lr
            )
        elif scheduler_type == 'step':
            self.scheduler = StepLR(
                self.optimizer,
                step_size=30,
                gamma=0.1
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è°ƒåº¦å™¨ç±»å‹: {scheduler_type}")
    
    def train_epoch(self, train_loader, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)
            
            # åº”ç”¨MixUpæˆ–CutMix
            if self.mixup is not None or self.cutmix is not None:
                use_augment = random.random() < self.use_augment_prob
                if use_augment:
                    if random.random() < 0.5 and self.mixup is not None:
                        data, target_a, target_b, lam = self.mixup(data, target)
                    elif self.cutmix is not None:
                        data, target_a, target_b, lam = self.cutmix(data, target)
                    mixed_target = True
                else:
                    mixed_target = False
            else:
                mixed_target = False
            
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨æ··åˆç²¾åº¦ï¼‰
            if self.use_amp:
                with torch.cuda.amp.autocast():
                    output = self.model(data)
                    if mixed_target:
                        loss = lam * self.criterion(output, target_a) + (1 - lam) * self.criterion(output, target_b)
                    else:
                        loss = self.criterion(output, target)
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                output = self.model(data)
                if mixed_target:
                    loss = lam * self.criterion(output, target_a) + (1 - lam) * self.criterion(output, target_b)
                else:
                    loss = self.criterion(output, target)
                
                loss.backward()
                self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            if not mixed_target:  # åªåœ¨éæ··åˆæ ‡ç­¾æ—¶è®¡ç®—å‡†ç¡®ç‡
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 100 == 0:
                print(f'Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}, LR: {self.optimizer.param_groups[0]["lr"]:.6f}')
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100. * correct / total if total > 0 else 0
        
        self.train_losses.append(avg_loss)
        self.train_accs.append(accuracy)
        self.learning_rates.append(self.optimizer.param_groups[0]['lr'])
        
        return avg_loss, accuracy
    
    def validate(self, val_loader):
        """éªŒè¯æ¨¡å¼"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        output = self.model(data)
                        loss = F.cross_entropy(output, target)  # éªŒè¯æ—¶ä¸ç”¨æ ‡ç­¾å¹³æ»‘
                else:
                    output = self.model(data)
                    loss = F.cross_entropy(output, target)
                
                total_loss += loss.item()
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)
        
        avg_loss = total_loss / len(val_loader)
        accuracy = 100. * correct / total
        
        self.val_losses.append(avg_loss)
        self.val_accs.append(accuracy)
        
        return avg_loss, accuracy
    
    def train(self, train_loader, val_loader, epochs, save_path='convnext_best.pth', class_names=None, class_to_idx=None):
        """å®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            epochs: è®­ç»ƒè½®æ•°
            save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            class_names: ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            class_to_idx: ç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆå¯é€‰ï¼‰
        """
        best_val_acc = 0
        
        print(f"å¼€å§‹è®­ç»ƒConvNeXtï¼Œå…±{epochs}ä¸ªepoch")
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"æ··åˆç²¾åº¦: {self.use_amp}")
        print("-" * 60)
        
        for epoch in range(epochs):
            start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, epoch)
            
            # éªŒè¯
            val_loss, val_acc = self.validate(val_loader)
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            
            epoch_time = time.time() - start_time
            
            # æ‰“å°ç»“æœ
            print(f"Epoch {epoch+1}/{epochs} ({epoch_time:.1f}s)")
            print(f"Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
            print(f"Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%")
            print(f"LR: {self.optimizer.param_groups[0]['lr']:.6f}")
            print("-" * 60)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                save_dict = {
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'best_val_acc': best_val_acc,
                    'train_losses': self.train_losses,
                    'val_losses': self.val_losses,
                    'train_accs': self.train_accs,
                    'val_accs': self.val_accs
                }
                
                # æ·»åŠ ç±»åˆ«ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
                if class_names is not None:
                    save_dict['class_names'] = class_names
                if class_to_idx is not None:
                    save_dict['class_to_idx'] = class_to_idx
                    
                torch.save(save_dict, save_path)
                print(f"âœ… æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜! Val Acc: {val_acc:.2f}%")
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        return best_val_acc
    
    def plot_training_curves(self, save_path='training_curves.png'):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¹¶ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¸å±•ç¤º"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(self.train_losses, label='Train Loss')
        axes[0, 0].plot(self.val_losses, label='Val Loss')
        axes[0, 0].set_title('Loss Curves')
        axes[0, 0].legend()
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(self.train_accs, label='Train Acc')
        axes[0, 1].plot(self.val_accs, label='Val Acc')
        axes[0, 1].set_title('Accuracy Curves')
        axes[0, 1].legend()
        # å­¦ä¹ ç‡æ›²çº¿
        axes[1, 0].plot(self.learning_rates)
        axes[1, 0].set_title('Learning Rate Schedule')
        # éªŒè¯å‡†ç¡®ç‡æ”¾å¤§
        axes[1, 1].plot(self.val_accs, 'g-', linewidth=2)
        axes[1, 1].set_title('Validation Accuracy Detail')
        axes[1, 1].grid(True)
        plt.tight_layout()
        fig.savefig(save_path)
        plt.close(fig)


# ===== 4. å¿«é€Ÿæµ‹è¯•æ¡†æ¶ =====

def create_dummy_dataset(num_samples=1000, num_classes=10, img_size=224):
    """åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•"""
    
    class DummyDataset(Dataset):
        def __init__(self, num_samples, num_classes, transform=None):
            self.num_samples = num_samples
            self.num_classes = num_classes
            self.transform = transform
        
        def __len__(self):
            return self.num_samples
        
        def __getitem__(self, idx):
            # éšæœºç”Ÿæˆå›¾åƒå’Œæ ‡ç­¾
            image = torch.randn(3, img_size, img_size)
            label = torch.randint(0, self.num_classes, (1,)).item()
            
            if self.transform:
                image = transforms.ToPILImage()(image)
                image = self.transform(image)
            
            return image, label
    
    return DummyDataset(num_samples, num_classes)


def quick_training_test():
    """å¿«é€Ÿè®­ç»ƒæµ‹è¯•"""
    print("=== ConvNeXtè®­ç»ƒæ¡†æ¶å¿«é€Ÿæµ‹è¯• ===\n")
    
    # å¯¼å…¥ä¹‹å‰å®ç°çš„ConvNeXt
    from ConvNeXtModel import convnext_tiny  # å‡è®¾ä¹‹å‰çš„æ¨¡å‹åœ¨è¿™ä¸ªæ–‡ä»¶ä¸­
    
    # è®¾ç½®å‚æ•°
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    num_classes = 10
    batch_size = 8
    img_size = 224
    
    # åˆ›å»ºæ¨¡å‹
    model = convnext_tiny(num_classes=num_classes)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # åˆ›å»ºæ•°æ®
    train_transform = ConvNeXtTransforms.get_train_transforms(img_size)
    val_transform = ConvNeXtTransforms.get_val_transforms(img_size)
    
    train_dataset = create_dummy_dataset(100, num_classes)
    val_dataset = create_dummy_dataset(50, num_classes)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ConvNeXtTrainer(
        model=model,
        device=device,
        num_classes=num_classes,
        use_amp=torch.cuda.is_available(),
        use_mixup=True,
        use_cutmix=True,
        label_smoothing=0.1
    )
    
    # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    trainer.setup_optimizer(learning_rate=1e-4, weight_decay=0.05)
    trainer.setup_scheduler(scheduler_type='cosine', epochs=5)
    
    # è®­ç»ƒå‡ ä¸ªepochæµ‹è¯•
    print("å¼€å§‹å¿«é€Ÿè®­ç»ƒæµ‹è¯•...")
    trainer.train(train_loader, val_loader, epochs=100)
    
    print("\nâœ… è®­ç»ƒæ¡†æ¶æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    quick_training_test()